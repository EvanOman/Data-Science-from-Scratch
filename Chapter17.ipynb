{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17: Decision Trees\n",
    "\n",
    "In this chapter we will implement a decision tree classifier. The decision tree will use entropy minimization for partion selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "\n",
    "Entropy is a measure of uncertainty: the lower the entropy, the lower the uncertainty. If we have a set of data $S$ consisting of observations with a finite set of labels $C_1, C_2, \\ldots C_n$. If each each class $C_i$ has corresponding proportion $p_i$,  the entropy of $S$ can then be defined as:\n",
    "\n",
    "$\\displaystyle H(S) = -p_1 \\log_2(p_1) - \\cdots - p_n \\log_2(p_n) = - \\sum_{i=1}^n p_i \\log_2(p_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c0429dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math, my_utils\n",
    "from collections import Counter, defaultdict\n",
    "from matplotlib import pyplot\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def p_log_p(p):\n",
    "    return -p * math.log(p, 2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = my_utils.linspace(0.001,1,100)\n",
    "    y = [p_log_p(x_i) for x_i in x]\n",
    "    pyplot.plot(x, y)\n",
    "    pyplot.title(\"Entropy Function\")\n",
    "    pyplot.xlabel(\"p\")\n",
    "    pyplot.ylabel(\"-p log p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(class_probabilities):\n",
    "    \"\"\"Given a list of class probabilities, compute the entropy\"\"\"\n",
    "    return sum(p_log_p(p)\n",
    "               for p in class_probabilities if p)\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probs = class_probabilities(labels)\n",
    "    return entropy(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy of a Partition\n",
    "\n",
    "Given some partitioning of our dataset into subsets $S_1, \\ldots, S_n$ with corresponding proportions $q_1, \\ldots, q_n$ then the entropy of that partitioning  is the weighted sum:\n",
    "\n",
    "$\\displaystyle H = q_1 H(S_1) + \\cdots + q_n H(S_n) = \\sum_i q_i H(S_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    \"\"\"find the entropy from this partition of the data into subsets\"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    \n",
    "    return sum(data_entropy(subset) * len(subset) / total_count \n",
    "               for subset in subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inputs = [({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'}, False),\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'}, False), \n",
    "        ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True), \n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'}, True),\n",
    "        ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'no'},      True),\n",
    "        ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'yes'},     False),\n",
    "        ({'level':'Mid', 'lang':'R', 'tweets':'yes', 'phd':'yes'},         True),\n",
    "        ({'level':'Senior', 'lang':'Python', 'tweets':'no', 'phd':'no'},  False),\n",
    "        ({'level':'Senior', 'lang':'R', 'tweets':'yes', 'phd':'no'},       True),\n",
    "        ({'level':'Junior', 'lang':'Python', 'tweets':'yes', 'phd':'no'},  True),\n",
    "        ({'level':'Senior', 'lang':'Python', 'tweets':'yes', 'phd':'yes'}, True),\n",
    "        ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'yes'},     True),\n",
    "        ({'level':'Mid', 'lang':'Java', 'tweets':'yes', 'phd':'no'},       True),\n",
    "        ({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"each input is a pair (attribute_dict, label)\n",
    "    returns a dict : attribute => inputs\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for input in inputs:\n",
    "        key = input[0][attribute] # get the value of the specified attribute\n",
    "        groups[key].append(input) # then add this input to the correct list\n",
    "    return groups\n",
    "\n",
    "def partition_entropy_by(inputs, attribute):\n",
    "    \"\"\"computes the entropy corresponding to the given partition\"\"\"\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level:\t 0.694\n",
      "lang:\t 0.860\n",
      "tweets:\t 0.788\n",
      "phd:\t 0.892\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for attr in ['level','lang','tweets','phd']: \n",
    "        print(\"{}:\\t {:1.3f}\".format(attr, partition_entropy_by(inputs, attr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Tree\n",
    "For the purpose of this algorithm we will implement a barebones tree structure where each node is either `True` or `False` (these being the leaf nodes) or a `(attr, subtree_dict)` tuple.\n",
    "\n",
    "Note that for attribute values not present in the training data we will no corresponding subtree. For these cases we will simply apply the most common decision label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    \"\"\"classify the input given a decision tree\"\"\"\n",
    "    \n",
    "    # if the tree is a leaf node, return the value\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "    \n",
    "    # otherwise this tree consists of an attribute to split on\n",
    "    # and a dictionary whose keys are values of that attribute\n",
    "    # and whose values are subtrees to consider next\n",
    "    attribute, subtree_dict = tree\n",
    "    \n",
    "    subtree_key = input.get(attribute)     # None if attribute not present\n",
    "    \n",
    "    if subtree_key not in subtree_dict:    # if no subtree for key,\n",
    "        subtree_key = None                 # we'll use the None subtree\n",
    "    \n",
    "    subtree = subtree_dict[subtree_key]    # choose the most appropriate subtree\n",
    "    return classify(subtree, input)        # and use it to classify the input\n",
    "\n",
    "def build_tree_id3(inputs, split_candidates=None):\n",
    "    \n",
    "    # if this is a first pass,\n",
    "    # all of the keys on the first input are split candidates\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "        \n",
    "    # counts true and falses in the inputs\n",
    "    num_inputs = len(inputs)\n",
    "    num_true = len([label for _, label in inputs if label])\n",
    "    num_false = num_inputs - num_true\n",
    "    \n",
    "    if num_true == 0: return False     # no trues? return false\n",
    "    if num_false == 0: return True      # no falses? return true\n",
    "    \n",
    "    if not split_candidates:            # if no splits left,  \n",
    "        return num_true >= num_falses  # return the majority leaf\n",
    "    \n",
    "    # otherwise split on the best attribute \n",
    "    best_attr = min(split_candidates, \n",
    "                    key=partial(partition_entropy_by, inputs))\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attr)\n",
    "    new_candidates = [a for a in split_candidates if a != best_attr]\n",
    "    \n",
    "    # rescursively build the subtrees\n",
    "    subtrees = {attribute_value: build_tree_id3(subset, new_candidates)\n",
    "                for attribute_value, subset in partitions.items()}\n",
    "    \n",
    "    subtrees[None] = num_true > num_false # default case\n",
    "    \n",
    "    return (best_attr, subtrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Apply Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('level', {'Mid': True, None: True, 'Senior': ('tweets', {'no': False, 'yes': True, None: False}), 'Junior': ('phd', {'no': True, 'yes': False, None: True})})\n",
      "The class of input one is True\n",
      "The class of input two is False\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tree = build_tree_id3(inputs)\n",
    "    \n",
    "    print(tree)\n",
    "    \n",
    "    class1 = classify(tree, { \"level\" : \"Junior\",\n",
    "                 \"lang\" : \"Java\",\n",
    "                 \"tweets\" : \"yes\",\n",
    "                 \"phd\" : \"no\"} )\n",
    "    \n",
    "    print(\"The class of input one is {0}\".format(class1))\n",
    "    \n",
    "    class2 = classify(tree, { \"level\" : \"Junior\",\n",
    "                 \"lang\" : \"Java\",\n",
    "                 \"tweets\" : \"yes\",\n",
    "                 \"phd\" : \"yes\"} )\n",
    "    \n",
    "    print(\"The class of input two is {0}\".format(class2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "As written, our decision tree will fit the training data perfectly. Clearly this will lead to masssive overfitting. There are several ways to change the Decision Tree implementation in order to fix the overfitting issue.\n",
    "\n",
    "Instead of considering those approaches we will implement a Random Forest model. Random Forests consist of a collection of Decision Trees which vote on which class to apply. Ideally these tree would be sufficiently varied in order to prevent the same overfitting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forest_classify(trees, input):\n",
    "    votes = [classify(tree, input) for tree in trees]\n",
    "    vote_counts = Counter(votes)\n",
    "    return vote_counts.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap Aggregating (Bagging)\n",
    "\n",
    "There are two different ways of making the random decision trees. First is Bootstrap Aggregating or Bagging. Bagging is the method of training a model on different subsets of the overall training set. IF we sample properly the trees we get from this method is sufficiently diverse.\n",
    "\n",
    "#### Ensembling\n",
    "\n",
    "Rather than vary the data used to train the tree, Ensembling changes the way the tree is formed. At each split decision we only consider a random subset of all of the features.\n",
    "\n",
    "```\n",
    "# if there's already few enough split candidates, look at all of them\n",
    "if len(split_candidates) <= self.num_split_candidates:\n",
    "sampled_split_candidates = split_candidates\n",
    "# otherwise pick a random sample\n",
    "else:\n",
    "sampled_split_candidates = random.sample(split_candidates,\n",
    "self.num_split_candidates)\n",
    "# now choose the best attribute only from those candidates\n",
    "best_attribute = min(sampled_split_candidates,\n",
    "key=partial(partition_entropy_by, inputs))\n",
    "partitions = partition_by(inputs, best_attribute)\n",
    "```\n",
    "\n",
    "By proceeding in this manner the trees should be sufficiently de-correlated for use in our random classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
